{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30271fa2-a8e1-4d6d-8a1b-2c855bb3e334",
   "metadata": {},
   "source": [
    "# Import the data into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9f9bf3-15f0-4fc7-b086-1501c4d5b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import praw\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Reddit API connection\n",
    "# reddit = praw.Reddit(\n",
    "#     client_id=\"\",\n",
    "#     client_secret=\"\",\n",
    "#     user_agent=\"\"\n",
    "# )\n",
    "\n",
    "# # Subreddits and search queries\n",
    "# subreddit_names = [\n",
    "#     \"disneyprincess\", \"movies\", \"shittymoviedetails\",\n",
    "#     \"IndianTeenagers\", \"disney\", \"Fantasy\"\n",
    "# ]\n",
    "\n",
    "# queries = [\"snow white\", \"snow white 2025\", \"snow white (2025)\"]\n",
    "# num_posts = 20\n",
    "\n",
    "\n",
    "# from_time = datetime(2025, 1, 1).timestamp()\n",
    "# to_time = datetime(2025, 5, 15, 23, 59, 59).timestamp()\n",
    "\n",
    "# # Data storage\n",
    "# data_with_submissions = {\"submissions\": []}\n",
    "# subreddit_post_counts = defaultdict(int)\n",
    "\n",
    "# # Counters\n",
    "# total_posts = 0\n",
    "# total_top_comments = 0\n",
    "# total_replies = 0\n",
    "\n",
    "# # Recursively extract comments and their replies\n",
    "# def extract_comment_data(comment):\n",
    "#     comment_entry = {\n",
    "#         \"author\": comment.author.name if comment.author else \"Deleted\",\n",
    "#         \"body\": comment.body,\n",
    "#         \"score\": comment.score,\n",
    "#         \"replies\": []\n",
    "#     }\n",
    "#     for reply in comment.replies:\n",
    "#         if isinstance(reply, praw.models.Comment):\n",
    "#             comment_entry[\"replies\"].append(extract_comment_data(reply))\n",
    "#     return comment_entry\n",
    "\n",
    "# # Loop through subreddits and queries\n",
    "# for subreddit_name in subreddit_names:\n",
    "#     subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "#     for query in queries:\n",
    "#         print(f\"Searching '{query}' in r/{subreddit_name}\")\n",
    "#         try:\n",
    "#             posts = subreddit.search(query, sort=\"top\", time_filter=\"all\", limit=num_posts * 2)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error fetching from r/{subreddit_name}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#         for post in posts:\n",
    "#             if post.num_comments == 0:\n",
    "#                 continue\n",
    "\n",
    "#             # Only keep posts created in 2024\n",
    "#             if not (from_time <= post.created_utc <= to_time):\n",
    "#                 continue\n",
    "\n",
    "#             post_data = {\n",
    "#                 \"title\": post.title,\n",
    "#                 \"author\": post.author,\n",
    "#                 \"score\": post.score,\n",
    "#                 \"created\": datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "#                 \"comments\": []\n",
    "#             }\n",
    "\n",
    "#             try:\n",
    "#                 post.comments.replace_more(limit=None)  # Load all comments\n",
    "#                 for top_comment in post.comments:\n",
    "#                     if isinstance(top_comment, praw.models.Comment):\n",
    "#                         comment_data = extract_comment_data(top_comment)\n",
    "#                         post_data[\"comments\"].append(comment_data)\n",
    "#                         total_top_comments += 1\n",
    "#                         total_replies += len(comment_data[\"replies\"])  # Count direct replies\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error loading comments: {e}\")\n",
    "#                 continue\n",
    "\n",
    "#             if post_data[\"comments\"]:\n",
    "#                 data_with_submissions[\"submissions\"].append(post_data)\n",
    "#                 subreddit_post_counts[subreddit_name] += 1\n",
    "#                 total_posts += 1\n",
    "\n",
    "# # Save to JSON\n",
    "# with open(\"Movie_AllComments_Final.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(data_with_submissions, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# # Print summary\n",
    "# print(f\"\\nSaved {total_posts} total posts with comments.\")\n",
    "# print(f\"Total top-level comments: {total_top_comments}\")\n",
    "# print(f\"Total replies (only direct replies counted): {total_replies}\")\n",
    "# print(f\"Total comments overall (minimum): {total_top_comments + total_replies}\\n\")\n",
    "\n",
    "# print(\"Breakdown by subreddit:\")\n",
    "# for name, count in subreddit_post_counts.items():\n",
    "#     print(f\"  - {name}: {count} posts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc3ab1-0aef-430c-b9bb-773948b0abb3",
   "metadata": {},
   "source": [
    "## Sample Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b391cede-7c1c-4e71-a3b2-6cf3b29460ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample JSON created: Movie_Comments_Sample_10MB.json (1.96 MB)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load the full JSON data\n",
    "with open(\"Movie_AllComments_Full.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    full_data = json.load(f)\n",
    "\n",
    "sample_data = {\"submissions\": []}\n",
    "target_size_mb = 1\n",
    "target_size_bytes = target_size_mb * 1024 * 1024  # 10MB in bytes\n",
    "\n",
    "current_size = 0\n",
    "\n",
    "for submission in full_data[\"submissions\"]:\n",
    "    sample_data[\"submissions\"].append(submission)\n",
    "    current_json = json.dumps(sample_data, ensure_ascii=False).encode(\"utf-8\")\n",
    "    current_size = len(current_json)\n",
    "    \n",
    "    if current_size >= target_size_bytes:\n",
    "        break\n",
    "\n",
    "# Write the 10MB sample to a new file\n",
    "with open(\"Movie_AllComments_Final.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sample_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Confirm size\n",
    "actual_size_mb = os.path.getsize(\"Movie_AllComments_Final.json\") / (1024 * 1024)\n",
    "print(f\"Sample JSON created: Movie_Comments_Sample_10MB.json ({actual_size_mb:.2f} MB)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
